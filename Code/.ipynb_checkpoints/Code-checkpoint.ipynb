{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0341dcef",
   "metadata": {},
   "source": [
    "## Set the computations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d64294-dfd4-4fc9-aedb-f97403713822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from plotnine import *\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b49e30-89d8-456e-8e37-6401471a0786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set visuales \n",
    "coloors = ['#739354', '#875590', '#7dd3ec','#f5c9d0' , '#7dd3ec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef18416a-d167-4d8b-a2f9-b2b36a0a5d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read major final demand sectors \n",
    "sectors = pd.read_excel('../Data/Meta.xlsx', sheet_name = 'Data').drop('Eora_classification', axis =1)\n",
    "sec_map = {1: 'Primary industry', 21 : 'Light manufacturing',23 : 'Heavey manufacturing', 3 : 'Tertiary industry' }\n",
    "sectors['Industry_category'] = sectors['Industry_category'].map(sec_map)\n",
    "sectors.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb168d5e-0851-47c8-9717-712c6377b39c",
   "metadata": {},
   "source": [
    "## 1. CES data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74c1ca-a109-4bdf-b398-e79cb0f8defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set general path \n",
    "ces_path = '../Data/CES/'\n",
    "# Read the CES data \n",
    "y = pd.read_csv(ces_path + 'urban.ces.csv')\n",
    "info = pd.read_csv('../infos.csv')\n",
    "y = pd.merge(info, y, left_on = 'Eora_country', right_on = 'Country iso3').drop('Eora_country', axis = 1)\n",
    "y.rename(columns = {'Country iso3': 'iso'}, inplace = True)\n",
    "y.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492cc1d2",
   "metadata": {},
   "source": [
    "## 2. Compute the TIV ($F$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6d8164-eebe-4f9e-af29-136807474c80",
   "metadata": {},
   "source": [
    "For this anlysis we're using [Eora26](https://worldmrio.com/eora26/) (v199.82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad14ca3-22ab-4322-a1d8-9c34b584fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read modules \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06d0afa",
   "metadata": {},
   "source": [
    "We need to compute the the Total Intensity Vector $(F)$ for these countries: *['CIV', 'MDV', 'MEX', 'DZA', 'LKA', 'CHN', 'BGD', 'ALB', 'ZWE','EGY', 'ZAF', 'MAR', 'NAM', 'BWA', 'VNM', 'ZMB', 'MNE', 'ASM', 'CRI', 'GEO', 'TUN']*\n",
    "\n",
    "To compute the the TIF, we need to preform the following operations: \n",
    "- compute the Xout \n",
    "- compute the direct intensity vector (f) \n",
    "- comput technical coefficient matrix\n",
    "- compute Wassily Leontief inverse \n",
    "- compute the Total intesnity verctor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9287b684-a5ec-43cd-9017-1bb1a1689e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths \n",
    "bp_path = '../Data/Eora/Eora_BP/'\n",
    "\n",
    "# Read the index \n",
    "index = [file for file in os.listdir(bp_path)]\n",
    "index\n",
    "\n",
    "containers = {}\n",
    "for i in index:\n",
    "    path = [file for file in os.listdir(bp_path + i) if any(map(str.isdigit, file))]\n",
    "    print(f' \\n i == {i} \\n')\n",
    "    container = {}\n",
    "    containers[i] = container\n",
    "    for m in path:\n",
    "        print(f'm == {m}')\n",
    "        read = pd.read_csv(bp_path + i + '/' + m, delimiter = '\\t', header = None)\n",
    "        container[m.split('_')[-1].split('.')[0]] = read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff7c624-3a82-4397-9042-91e2efd1f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the xout for the basic prices and purchaser prices \n",
    "\n",
    "BP = {}\n",
    "print('BB values')\n",
    "# set the computation code \n",
    "for i in containers.keys():\n",
    "    # print('---')\n",
    "    # print(i)\n",
    "    # print('---')\n",
    "    for m in containers.get(i):\n",
    "        \"\"\" interate over the dic and return the xout for each years\"\"\"\n",
    "        np.seterr(divide='ignore', invalid='ignore')\n",
    "        xout = np.empty((4915,1))\n",
    "        np.add(np.add.reduce(np.array(containers.get(i).get('T')), axis =1)[:, np.newaxis], np.add.reduce(np.array(containers.get(i).get('FD')), axis =1)[:, np.newaxis], out = xout)\n",
    "        BP[i.split('_')[1]] = xout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e808e2a6-47f8-4feb-91f5-7297efb68e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the tables in PP \n",
    "\n",
    "# set paths \n",
    "pp_path = '../Data/Eora/Eora_PP/'\n",
    "\n",
    "# Read the index \n",
    "dex = [file for file in os.listdir(pp_path)]\n",
    "\n",
    "conts = {}\n",
    "for i in dex:\n",
    "    path = [file for file in os.listdir(pp_path + i) if any(map(str.isdigit, file))]\n",
    "    print(f' \\n i == {i} \\n')\n",
    "    container = {}\n",
    "    conts[i] = container\n",
    "    for m in path:\n",
    "        print(f'm == {m}')\n",
    "        read = pd.read_csv(pp_path + i + '/' + m, delimiter = '\\t', header = None)\n",
    "        container[m.split('_')[-1].split('.')[0]] = read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec5dda-9e49-4aeb-ba94-402a9f3bdc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "PP = {}\n",
    "print('PP values')\n",
    "# set the computation code \n",
    "for i in conts.keys():\n",
    "    print('---')\n",
    "    print(i)\n",
    "    print('---')\n",
    "    for m in conts.get(i):\n",
    "        \"\"\" interate over the dic and return the xout for each of the years\"\"\"\n",
    "        np.seterr(divide='ignore', invalid='ignore')\n",
    "        xout = np.empty((4915,1))\n",
    "        np.add(np.add.reduce(np.array(conts.get(i).get('T')), axis =1)[:, np.newaxis], np.add.reduce(np.array(conts.get(i).get('FD')), axis =1)[:, np.newaxis], out = xout)\n",
    "        PP[i.split('_')[1]] = xout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf90e96-a13f-4fc9-a91e-30b79aa5e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compte the fraction PP/BP\n",
    "years = np.arange(2009, 2016).astype('str')\n",
    "frac = {}\n",
    "for year in years: \n",
    "    frac[year] = BP.get(year) / PP.get(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a750535-a9a3-47f8-b717-5b4fe145eb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check the Q-values index\n",
    "Q = pd.read_csv('../Data/Eora/Eora_BP/Eora26_2009_bp/Eora26_2009_bp_Q.txt', delimiter = '\\t', header = None)\n",
    "I = pd.read_csv('../Data/Eora/Eora_BP/Eora26_2009_bp/labels_Q.txt', delimiter = '\\t', header = None)\n",
    "lo = pd.concat([I, Q], axis = 1)\n",
    "lo.iloc[2501,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d31c1-e696-4113-bc0c-db3220ed82bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Blue = {}\n",
    "print('Blue water footprint')\n",
    "# set the computation code \n",
    "for i in containers.keys():\n",
    "    # print('---')\n",
    "    # print(i)\n",
    "    # print('---')\n",
    "    for m in containers.get(i):\n",
    "        \"\"\" interate over the dic and return the TIV for each of the years\"\"\"\n",
    "        np.seterr(divide='ignore', invalid='ignore')\n",
    "        xout = np.empty((4915,1))\n",
    "        np.add(np.add.reduce(np.array(containers.get(i).get('T')), axis =1)[:, np.newaxis], np.add.reduce(np.array(containers.get(i).get('FD')), axis =1)[:, np.newaxis], out = xout)\n",
    "        # compute direct intensity vector (f) \n",
    "        f = np.zeros_like(xout)\n",
    "        np.divide(np.array(containers.get(i).get('Q'))[2500,:][:, np.newaxis], xout, out=f, where= xout != 0)\n",
    "        # comput technical coefficient matrix \n",
    "        A = np.empty((4915, 4915))\n",
    "        np.divide(containers.get(i).get('T'), xout, out = A)\n",
    "        A = np.array(pd.DataFrame(A).fillna(0))\n",
    "        # creating identity matrix \n",
    "        I = np.eye(4915)\n",
    "        # compute the Wassily Leontief inverse \n",
    "        L = np.linalg.inv((I - A)) \n",
    "        # compute the Total intesnity verctor \n",
    "        F = L.dot(f)\n",
    "        Blue[i.split('_')[1]] = F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f890a126-3607-4d06-aeb8-51087bbc8303",
   "metadata": {},
   "outputs": [],
   "source": [
    "Grey = {}\n",
    "# set the computation code \n",
    "print('Grey water footprint')\n",
    "for i in containers.keys():\n",
    "    print('---')\n",
    "    print(i)\n",
    "    print('---')\n",
    "    for m in containers.get(i):\n",
    "        \"\"\" interate over the dic and return the TIV for each of the years\"\"\"\n",
    "        np.seterr(divide='ignore', invalid='ignore')\n",
    "        xout = np.empty((4915,1))\n",
    "        np.add(np.add.reduce(np.array(containers.get(i).get('T')), axis =1)[:, np.newaxis], np.add.reduce(np.array(containers.get(i).get('FD')), axis =1)[:, np.newaxis], out = xout)\n",
    "        # compute direct intensity vector (f) \n",
    "        f = np.zeros_like(xout)\n",
    "        np.divide(np.array(containers.get(i).get('Q'))[2501,:][:, np.newaxis], xout, out=f, where= xout != 0)\n",
    "        # comput technical coefficient matrix \n",
    "        A = np.empty((4915, 4915))\n",
    "        np.divide(containers.get(i).get('T'), xout, out = A)\n",
    "        A = np.array(pd.DataFrame(A).fillna(0))\n",
    "        # creating identity matrix \n",
    "        I = np.eye(4915)\n",
    "        # compute the Wassily Leontief inverse \n",
    "        L = np.linalg.inv((I - A)) \n",
    "        # compute the Total intesnity verctor \n",
    "        F = L.dot(f)\n",
    "        Grey[i.split('_')[1]] = F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f631ce8a-3306-404e-aa3b-45e837f300f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the index of countries & sectors \n",
    "index = pd.read_csv('../Data/Eora/Eora_BP/Eora26_2009_bp/labels_T.txt', delimiter = '\\t', header = None).iloc[:,:-1]\n",
    "index.columns = ['country', 'iso3', 'industries', 'sector']\n",
    "index.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8486fd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add metadata to the frac dic \n",
    "for i in frac.keys():\n",
    "    frac[i] = pd.concat([index, pd.DataFrame(frac.get(i))], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7102246",
   "metadata": {},
   "source": [
    "### Convert PP to BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d05cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a569e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y['iso'] == \"DZA\"].iloc[:,5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fafc683",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(frac.get('2011').query(f'iso3 == \"DZA\"').iloc[:,-1])[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e4b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y['iso'] == \"DZA\"]['City'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15460356",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_adjusted = {}\n",
    "# downscale from PP to BP \n",
    "for name in y['iso'].unique():\n",
    "    year = y[y['iso'] == name]['Year'].unique().item()\n",
    "    f = np.array(frac.get(str(year)).query(f'iso3 == \"{name}\"').iloc[:,-1])[:, np.newaxis]\n",
    "    yy = np.array(y[y['iso'] == f\"{name}\"].iloc[:,5:].T)\n",
    "    corrected = yy * f\n",
    "    y_adjusted[name] = corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out = []\n",
    "\n",
    "for i in y_adjusted.keys():\n",
    "    y_out.append(pd.DataFrame(y_adjusted.get(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ds = pd.concat(y_out, axis = 1)\n",
    "y_ds.columns = y.iso\n",
    "y_ds = abs(y_ds)\n",
    "y_ds = y_ds.T.reset_index()\n",
    "y_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198c0210",
   "metadata": {},
   "source": [
    "## Computing the virtual water -Grey & Bleu- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98540b0-01e1-4471-aaca-87b76928b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add the countries and the sectors names \n",
    "for i in Blue.keys():\n",
    "    Blue[i] = pd.concat([index, pd.DataFrame(Blue.get(i))], axis = 1)\n",
    "    \n",
    "for i in Grey.keys():\n",
    "    Grey[i] = pd.concat([index, pd.DataFrame(Grey.get(i))], axis = 1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290971a7-1faf-4ca2-998d-8a954be6f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the TIV for each country & year \n",
    "info = pd.read_csv('../infos.csv')\n",
    "info.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e9dd4-b8bd-4217-849a-7f1e8d0d5cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the data for each year & country \n",
    "Bleu_F = {}\n",
    "for i in info['Eora_country'].unique():\n",
    "    Year = info[info['Eora_country'] == i].Year.item()\n",
    "    Bleu_F[i] = Blue.get(f\"{Year}\").query(f'iso3 == \"{i}\"')[['iso3', 'sector', 0]]\n",
    "    \n",
    "Grey_F = {}\n",
    "for i in info['Eora_country'].unique():\n",
    "    Year = info[info['Eora_country'] == i].Year.item()\n",
    "    Grey_F[i] = Grey.get(f\"{Year}\").query(f'iso3 == \"{i}\"')[['iso3', 'sector', 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e9cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ds[y_ds['iso'] == \"CHN\"].iloc[:,2:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d365206-5b02-4474-a713-1ca44b970d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the footprints \n",
    "\n",
    "Bleu_foot = {}\n",
    "\n",
    "for name in Bleu_F.keys(): \n",
    "    city = np.array(y_ds[y_ds['iso'] == f'{name}'].iloc[:,1:].T)\n",
    "    TIF = np.array(Bleu_F.get(f'{name}')[[0]])\n",
    "    com = pd.DataFrame(city * TIF)\n",
    "#     com.columns = y[y['iso'] == f'{name}'].iloc[:,1:].T.columns   \n",
    "    Bleu_foot[name] = com\n",
    "    \n",
    "Grey_foot = {}\n",
    "\n",
    "for name in Grey_F.keys(): \n",
    "    city = np.array(y_ds[y_ds['iso'] == f'{name}'].iloc[:,1:].T)\n",
    "    TIF = np.array(Grey_F.get(f'{name}')[[0]])\n",
    "    com = pd.DataFrame(city * TIF)\n",
    "#     com.columns = y[y['Country iso3'] == f'{name}'].iloc[:,2:].T.columns   \n",
    "    Grey_foot[name] = com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f751b1-5ca4-4aa4-9c2e-0b080dc39cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## take the dfs \n",
    "Bleu = pd.concat([Bleu_foot.get(i) for i in Bleu_foot.keys()], axis =1)\n",
    "Grey = pd.concat([Grey_foot.get(i) for i in Grey_foot.keys()], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09970c0d-2450-4b29-b278-7922dd3c1534",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bleu = pd.concat([sectors, Bleu * 1000], axis =1)\n",
    "Grey = pd.concat([sectors, Grey * 1000], axis =1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b309716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bleu.columns = ['Sector', 'Indus_Sector','Algiers',\n",
    " 'Tunis',\n",
    " 'Casablanca',\n",
    " 'Guelmim',\n",
    " 'Khenifra',\n",
    " 'Laayoun',\n",
    " 'Marrakesh',\n",
    " 'Oriental',\n",
    " 'Souss',\n",
    " 'Tafilalet',\n",
    " 'Tangier',\n",
    " 'Berat',\n",
    " 'Diber',\n",
    " 'Durres',\n",
    " 'Elbasan',\n",
    " 'Gjirokaster',\n",
    " 'Korce',\n",
    " 'Kukes',\n",
    " 'Lezhe',\n",
    " 'Shkoder',\n",
    " 'Tirana',\n",
    " 'Vlore',\n",
    " 'Barishal',\n",
    " 'Chittagong',\n",
    " 'Dhaka',\n",
    " 'Khulna',\n",
    " 'Rajshahi',\n",
    " 'Rangpur',\n",
    " 'Sylhet',\n",
    " 'Gaborone',\n",
    " 'San Jose',\n",
    " 'Abidjan',\n",
    " 'Agneby-Tiassa',\n",
    " 'Bafing',\n",
    " 'Bagoue',\n",
    " 'Belier',\n",
    " 'Bere',\n",
    " 'Boukani',\n",
    " 'Cavally',\n",
    " 'Folon',\n",
    " 'Gbeke',\n",
    " 'Gbokie',\n",
    " 'Goh',\n",
    " 'Gontougo',\n",
    " 'Grand-Ponts',\n",
    " 'Guemon',\n",
    " 'Hambol',\n",
    " 'Haut-Sassandra',\n",
    " 'Iffou',\n",
    " 'Indenie-Djuablin',\n",
    " 'Kabadougou',\n",
    " 'La Me',\n",
    " 'Loh-Djiboua',\n",
    " 'Marahoue',\n",
    " 'Moronou',\n",
    " 'N-zi',\n",
    " 'Nawa',\n",
    " 'Poro',\n",
    " 'San-Pedro',\n",
    " 'Sud-Comoe',\n",
    " 'Tchologo',\n",
    " 'Tonkpi',\n",
    " 'Worodougou',\n",
    " 'Yamoussoukro',\n",
    " 'Addu',\n",
    " 'Atolls',\n",
    " 'Faadhippolhu',\n",
    " 'Felidhy Atoll',\n",
    " 'Gnaviyani',\n",
    " 'Hadhdhuumathi',\n",
    " 'Kolhumadulu',\n",
    " 'Male',\n",
    " 'Mulakatholhu',\n",
    " 'Montenegro',\n",
    " 'Erongo',\n",
    " 'Hardap',\n",
    " 'Keras',\n",
    " 'Kunene',\n",
    " 'Omaheke',\n",
    " 'Omusti',\n",
    " 'Oshana',\n",
    " 'Oshikoto',\n",
    " 'Otjiwarongo',\n",
    " 'Zambezi',\n",
    " 'Cape Town',\n",
    " 'Gauteng',\n",
    " 'Limpopo',\n",
    " 'Mpumalang',\n",
    " 'Amparai',\n",
    " 'Anuradhapura',\n",
    " 'Badulla',\n",
    " 'Batticaloa',\n",
    " 'Colombo',\n",
    " 'Galle',\n",
    " 'Gampaha',\n",
    " 'Hambantota',\n",
    " 'Jaffna',\n",
    " 'Kalutara',\n",
    " 'Kandy',\n",
    " 'Kegalla',\n",
    " 'Kilinochchi',\n",
    " 'Kurunegala',\n",
    " 'Mannar',\n",
    " 'Matale',\n",
    " 'Matara',\n",
    " 'Monaragala',\n",
    " 'Mullaitivu',\n",
    " 'Nuwar Eliya',\n",
    " 'Polonnaruwa',\n",
    " 'Puttalama',\n",
    " 'Ratnapura',\n",
    " 'Trincomalee',\n",
    " 'Vavuniya',\n",
    " 'Ha Noi',\n",
    " 'Lusaka',\n",
    " 'Tbilisi',\n",
    " 'Aguascalientes',\n",
    " 'Baja California Sur',\n",
    " 'Baja California',\n",
    " 'Campeche',\n",
    " 'Chiapas',\n",
    " 'Chihuahua',\n",
    " 'Coahuila de Zaragoza',\n",
    " 'Colima',\n",
    " 'Cuidad de Mexico',\n",
    " 'Durango',\n",
    " 'Guanajuato',\n",
    " 'Hidalgo',\n",
    " 'Leon',\n",
    " 'Melchor Ocampo',\n",
    " 'Morelos',\n",
    " 'Nayarit',\n",
    " 'Oaxaca',\n",
    " 'Ojuelos de Jalisco',\n",
    " 'Puebla',\n",
    " 'Queretaro',\n",
    " 'Quintana Roo',\n",
    " 'San Luis Potosi',\n",
    " 'Sinaloa',\n",
    " 'Sonora',\n",
    " 'Tabasco',\n",
    " 'Tamaumipas',\n",
    " 'Tlaxcala',\n",
    " 'Veracruz',\n",
    " 'Vicente Guerrero',\n",
    " 'Yucatan',\n",
    " 'Zacatlan',\n",
    " 'Byo',\n",
    " 'Hre',\n",
    " 'Mach-Central',\n",
    " 'Manicaland',\n",
    " 'Mash-West',\n",
    " 'Mash',\n",
    " 'Mat-North',\n",
    " 'Mat-South',\n",
    " 'Mavingo',\n",
    " 'Mid-lands',\n",
    " 'Anhui',\n",
    " 'Beijing',\n",
    " 'Chongqing',\n",
    " 'Fujian',\n",
    " 'Gansu',\n",
    " 'Guangdong',\n",
    " 'Guangxi',\n",
    " 'Guizhou',\n",
    " 'Hainan',\n",
    " 'Hebei',\n",
    " 'Heilongjiang',\n",
    " 'Henan',\n",
    " 'Hubei',\n",
    " 'Hunan',\n",
    " 'Inner Mongolia',\n",
    " 'Jiangsu',\n",
    " 'Jiangxi',\n",
    " 'Jilin',\n",
    " 'Liaoning',\n",
    " 'Ningxia',\n",
    " 'Qinghai',\n",
    " 'Shaanxi',\n",
    " 'Shandong',\n",
    " 'Shanxi',\n",
    " 'Sichuan',\n",
    " 'Tianjin',\n",
    " 'Tibet',\n",
    " 'Xinjiang',\n",
    " 'Yunnan']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cdd5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Grey.columns = ['Sector', 'Indus_Sector','Algiers',\n",
    " 'Tunis',\n",
    " 'Casablanca',\n",
    " 'Guelmim',\n",
    " 'Khenifra',\n",
    " 'Laayoun',\n",
    " 'Marrakesh',\n",
    " 'Oriental',\n",
    " 'Souss',\n",
    " 'Tafilalet',\n",
    " 'Tangier',\n",
    " 'Berat',\n",
    " 'Diber',\n",
    " 'Durres',\n",
    " 'Elbasan',\n",
    " 'Gjirokaster',\n",
    " 'Korce',\n",
    " 'Kukes',\n",
    " 'Lezhe',\n",
    " 'Shkoder',\n",
    " 'Tirana',\n",
    " 'Vlore',\n",
    " 'Barishal',\n",
    " 'Chittagong',\n",
    " 'Dhaka',\n",
    " 'Khulna',\n",
    " 'Rajshahi',\n",
    " 'Rangpur',\n",
    " 'Sylhet',\n",
    " 'Gaborone',\n",
    " 'San Jose',\n",
    " 'Abidjan',\n",
    " 'Agneby-Tiassa',\n",
    " 'Bafing',\n",
    " 'Bagoue',\n",
    " 'Belier',\n",
    " 'Bere',\n",
    " 'Boukani',\n",
    " 'Cavally',\n",
    " 'Folon',\n",
    " 'Gbeke',\n",
    " 'Gbokie',\n",
    " 'Goh',\n",
    " 'Gontougo',\n",
    " 'Grand-Ponts',\n",
    " 'Guemon',\n",
    " 'Hambol',\n",
    " 'Haut-Sassandra',\n",
    " 'Iffou',\n",
    " 'Indenie-Djuablin',\n",
    " 'Kabadougou',\n",
    " 'La Me',\n",
    " 'Loh-Djiboua',\n",
    " 'Marahoue',\n",
    " 'Moronou',\n",
    " 'N-zi',\n",
    " 'Nawa',\n",
    " 'Poro',\n",
    " 'San-Pedro',\n",
    " 'Sud-Comoe',\n",
    " 'Tchologo',\n",
    " 'Tonkpi',\n",
    " 'Worodougou',\n",
    " 'Yamoussoukro',\n",
    " 'Addu',\n",
    " 'Atolls',\n",
    " 'Faadhippolhu',\n",
    " 'Felidhy Atoll',\n",
    " 'Gnaviyani',\n",
    " 'Hadhdhuumathi',\n",
    " 'Kolhumadulu',\n",
    " 'Male',\n",
    " 'Mulakatholhu',\n",
    " 'Montenegro',\n",
    " 'Erongo',\n",
    " 'Hardap',\n",
    " 'Keras',\n",
    " 'Kunene',\n",
    " 'Omaheke',\n",
    " 'Omusti',\n",
    " 'Oshana',\n",
    " 'Oshikoto',\n",
    " 'Otjiwarongo',\n",
    " 'Zambezi',\n",
    " 'Cape Town',\n",
    " 'Gauteng',\n",
    " 'Limpopo',\n",
    " 'Mpumalang',\n",
    " 'Amparai',\n",
    " 'Anuradhapura',\n",
    " 'Badulla',\n",
    " 'Batticaloa',\n",
    " 'Colombo',\n",
    " 'Galle',\n",
    " 'Gampaha',\n",
    " 'Hambantota',\n",
    " 'Jaffna',\n",
    " 'Kalutara',\n",
    " 'Kandy',\n",
    " 'Kegalla',\n",
    " 'Kilinochchi',\n",
    " 'Kurunegala',\n",
    " 'Mannar',\n",
    " 'Matale',\n",
    " 'Matara',\n",
    " 'Monaragala',\n",
    " 'Mullaitivu',\n",
    " 'Nuwar Eliya',\n",
    " 'Polonnaruwa',\n",
    " 'Puttalama',\n",
    " 'Ratnapura',\n",
    " 'Trincomalee',\n",
    " 'Vavuniya',\n",
    " 'Ha Noi',\n",
    " 'Lusaka',\n",
    " 'Tbilisi',\n",
    " 'Aguascalientes',\n",
    " 'Baja California Sur',\n",
    " 'Baja California',\n",
    " 'Campeche',\n",
    " 'Chiapas',\n",
    " 'Chihuahua',\n",
    " 'Coahuila de Zaragoza',\n",
    " 'Colima',\n",
    " 'Cuidad de Mexico',\n",
    " 'Durango',\n",
    " 'Guanajuato',\n",
    " 'Hidalgo',\n",
    " 'Leon',\n",
    " 'Melchor Ocampo',\n",
    " 'Morelos',\n",
    " 'Nayarit',\n",
    " 'Oaxaca',\n",
    " 'Ojuelos de Jalisco',\n",
    " 'Puebla',\n",
    " 'Queretaro',\n",
    " 'Quintana Roo',\n",
    " 'San Luis Potosi',\n",
    " 'Sinaloa',\n",
    " 'Sonora',\n",
    " 'Tabasco',\n",
    " 'Tamaumipas',\n",
    " 'Tlaxcala',\n",
    " 'Veracruz',\n",
    " 'Vicente Guerrero',\n",
    " 'Yucatan',\n",
    " 'Zacatlan',\n",
    " 'Byo',\n",
    " 'Hre',\n",
    " 'Mach-Central',\n",
    " 'Manicaland',\n",
    " 'Mash-West',\n",
    " 'Mash',\n",
    " 'Mat-North',\n",
    " 'Mat-South',\n",
    " 'Mavingo',\n",
    " 'Mid-lands',\n",
    " 'Anhui',\n",
    " 'Beijing',\n",
    " 'Chongqing',\n",
    " 'Fujian',\n",
    " 'Gansu',\n",
    " 'Guangdong',\n",
    " 'Guangxi',\n",
    " 'Guizhou',\n",
    " 'Hainan',\n",
    " 'Hebei',\n",
    " 'Heilongjiang',\n",
    " 'Henan',\n",
    " 'Hubei',\n",
    " 'Hunan',\n",
    " 'Inner Mongolia',\n",
    " 'Jiangsu',\n",
    " 'Jiangxi',\n",
    " 'Jilin',\n",
    " 'Liaoning',\n",
    " 'Ningxia',\n",
    " 'Qinghai',\n",
    " 'Shaanxi',\n",
    " 'Shandong',\n",
    " 'Shanxi',\n",
    " 'Sichuan',\n",
    " 'Tianjin',\n",
    " 'Tibet',\n",
    " 'Xinjiang',\n",
    " 'Yunnan']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0135950-132b-4136-8c65-3fed78b6574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bleu = Bleu.melt(id_vars = ['Sector', 'Indus_Sector'], var_name = 'City')\n",
    "Bleu['Type'] = 'Bleu water'\n",
    "Grey = Grey.melt(id_vars = ['Sector', 'Indus_Sector'], var_name = 'City')\n",
    "Grey['Type'] = 'Grey water'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ed9aa-8331-464a-8786-f59e8ad837d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = pd.concat([Bleu, Grey], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6440b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c882b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot.to_excel('../Output/ds.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c1469-16cf-416b-b04f-1326af225b54",
   "metadata": {
    "tags": []
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5ec605-ef57-4567-86a5-49164f0d6eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_excel('../Output/ds.xlsx')\n",
    "ds = ds[~(ds['City'].isin(['Colombo', 'Gampaha',\n",
    "                                 'Kalutara', 'Trincomalee',\n",
    "                                 'Matara']))]\n",
    "index = pd.read_csv('../Data/index.csv')\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.merge(ds, index, on = 'City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07011727",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = ds.groupby(['City', 'Type']).sum().reset_index()\n",
    "pd.merge(city, index, on = 'City').groupby(['Type', 'Continent ']).agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e483eec6",
   "metadata": {},
   "source": [
    "### Top 20 cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87624a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.query('Type == \"Bleu water\"').groupby('City').sum().sort_values(by = 'value', ascending =False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd71d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e093a0-0893-468a-a16f-7a7a6bd21b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.Type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805e2a3d-0117-405b-97ff-d1e5c61b7c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "((ds.query('Type == \"Grey water\"').groupby('Sector')[['value']].mean() / \\\n",
    "  ds.query('Type == \"Grey water\"').groupby('Sector')[['value']].mean().sum()) \\\n",
    " * 100).sort_values(by = 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e635988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = (ds[(ds['Continent '] != 'Europe')].groupby(\n",
    "    ['Sector', 'Category'])).mean().query('Category == \"UMIC\"').reset_index()\n",
    "mm = m['value'].sum()\n",
    "m['value'] = (m['value'] / mm) * 100\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a46a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (ds[(ds['Continent '] != 'Europe')].groupby(\n",
    "    ['Sector', 'Category', \"Type\"]).mean().reset_index()\n",
    "    .query('Category == \"UMIC\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aefa628",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = d.query('Type == \"Grey water\"').copy()\n",
    "sumo = f['value'].sum()\n",
    "f['value'] = (f['value'] / sumo) * 100\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa2fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.query('Category == \"LMIC\" & Type == \"Grey water\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0177e983-d917-4247-88e0-0fb9853f196b",
   "metadata": {},
   "source": [
    "# Maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025be8ef-fd27-432a-a0df-3e208179898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import geopandas as gpd\n",
    "from cartopy import crs as ccrs\n",
    "from shapely.geometry import Point, LineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc5ec21-64bb-4207-846c-12cf80763461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize = (19,19))\n",
    "# world.query('continent == \"Asia\"').dissolve().plot(facecolor = 'w', ax=ax, hatch = '////', alpha = .2, zorder = 0)\n",
    "# world.query('continent == \"South America\"').dissolve().plot(facecolor = 'w', ax=ax, hatch = '////', alpha = .2, zorder = 0)\n",
    "# world.query('continent == \"Africa\"').dissolve().plot(facecolor = 'w', ax=ax, hatch = '////', alpha = .2, zorder = 0)\n",
    "# world.query('continent != \"Antarctica\"').plot(ax =ax, color = 'grey', alpha = .2, zorder = 0)\n",
    "\n",
    "# plt.axis('off')\n",
    "# plt.savefig('../Figures/map.png', dpi = 500)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e187f4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "cities = gpd.read_file(gpd.datasets.get_path('naturalearth_cities'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874e91ec-cd9a-4198-88f1-431b0c7a663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3335b00-a87f-40ac-b163-e86038855852",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the data \n",
    "\n",
    "# set paths \n",
    "bp_path = '../Data/Eora/Eora_BP/'\n",
    "\n",
    "# Read the index \n",
    "index = [file for file in os.listdir(bp_path) if not file.endswith('.zip')]\n",
    "index\n",
    "\n",
    "containers = {}\n",
    "for i in index:\n",
    "    path = [file for file in os.listdir(bp_path + i) if any(map(str.isdigit, file))]\n",
    "    print(f' \\n i == {i} \\n')\n",
    "    container = {}\n",
    "    containers[i] = container\n",
    "    for m in path:\n",
    "        read = pd.read_csv(bp_path + i + '/' + m, delimiter = '\\t', header = None)\n",
    "        container[m.split('_')[-1].split('.')[0]] = read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940885e5-81fa-4730-a34a-4236f56b20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.read_csv('../Data/Eora/Eora_BP/Eora26_2011_bp/labels_T.txt', sep = '\\t', header = None)\n",
    "index.columns = ['country', 'industry', 'iso', 'sector', 'Na']\n",
    "index.drop('Na', axis = 1, inplace = True)\n",
    "index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01b05d6-63d9-4f9b-9cc6-d596e796ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {}\n",
    "\n",
    "for key in containers.keys():\n",
    "    m[key] = containers.get(key).get('T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d8259f-09cb-444a-bcd7-3dc495534c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for key in m.keys():\n",
    "    m.get(key).columns = index.country\n",
    "    data = pd.concat([index, m.get(key)], axis =1)\n",
    "    d[key.split('_')[1]] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35ee6cf-25a1-4c2f-be0c-6547ae1f158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tunisia 2010 \n",
    "tunisia = d.get('2010').query('country == \"Tunisia\"').groupby(level=0, axis=1) \\\n",
    ".sum().drop(['country', 'industry', 'iso', 'sector'], axis =1).sum() \\\n",
    ".to_frame().sort_values(by = 0, ascending = False).head(40)\n",
    "tun = world[world['name'].isin(tunisia.index.tolist())]\n",
    "tun['id'] = 1\n",
    "## Algeria 2011\n",
    "algeria = d.get('2011').query('country == \"Algeria\"').groupby(level=0, axis=1) \\\n",
    ".sum().drop(['country', 'industry', 'iso', 'sector'], axis =1).sum() \\\n",
    ".to_frame().sort_values(by = 0, ascending = False).head(40)\n",
    "dza = world[world['name'].isin(algeria.index.tolist())]\n",
    "dza['id'] = 1\n",
    "\n",
    "## Morocco 2014 \n",
    "morocco = d.get('2014').query('country == \"Morocco\"').groupby(level=0, axis=1) \\\n",
    ".sum().drop(['country', 'industry', 'iso', 'sector'], axis =1).sum() \\\n",
    ".to_frame().sort_values(by = 0, ascending = False).head(40)\n",
    "mor = world[world['name'].isin(morocco.index.tolist())]\n",
    "mor['id'] = 1\n",
    "\n",
    "## Mexico \n",
    "mexico = d.get('2015').query('country == \"Mexico\"').groupby(level=0, axis=1) \\\n",
    ".sum().drop(['country', 'industry', 'iso', 'sector'], axis =1).sum() \\\n",
    ".to_frame().sort_values(by = 0, ascending = False).head(40)\n",
    "mex = world[world['name'].isin(mexico.index.tolist())]\n",
    "mex['id'] = 1\n",
    "\n",
    "## China\n",
    "china = d.get('2014').query('country == \"China\"').groupby(level=0, axis=1) \\\n",
    ".sum().drop(['country', 'industry', 'iso', 'sector'], axis =1).sum() \\\n",
    ".to_frame().sort_values(by = 0, ascending = False).head(40)\n",
    "chi = world[world['name'].isin(china.index.tolist())]\n",
    "chi['id'] = 1\n",
    "\n",
    "## South Africa \n",
    "south = d.get('2015').query('country == \"South Africa\"').groupby(level=0, axis=1) \\\n",
    ".sum().drop(['country', 'industry', 'iso', 'sector'], axis =1).sum() \\\n",
    ".to_frame().sort_values(by = 0, ascending = False).head(40)\n",
    "sou = world[world['name'].isin(south.index.tolist())]\n",
    "sou['id'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3943a69-5e9d-4946-93b7-01431e96b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate centroids and plot\n",
    "world['center'] = world.geometry.centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018befcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tunisia \n",
    "tu = gpd.GeoDataFrame()\n",
    "tu['Point_B'] = gpd.GeoSeries(Point(9.53472, 34.17294))\n",
    "tu['id'] = 1\n",
    "\n",
    "tun = gpd.GeoDataFrame(pd.merge(tun, tu, on = 'id'))\n",
    "tun['line'] = tun.apply(lambda x: LineString([x['Point_B'], x['center']]), axis=1)\n",
    "tun_gdf = gpd.GeoDataFrame(tun, geometry=tun['line'])\n",
    "\n",
    "## Morroco \n",
    "mo = gpd.GeoDataFrame()\n",
    "mo['Point_B'] = gpd.GeoSeries(Point(-8.42048, 29.88539))\n",
    "mo['id'] = 1\n",
    "\n",
    "mor = gpd.GeoDataFrame(pd.merge(mor, mo, on = 'id'))\n",
    "mor['line'] = mor.apply(lambda x: LineString([x['Point_B'], x['center']]), axis=1)\n",
    "mor_gdf = gpd.GeoDataFrame(mor, geometry=mor['line'])\n",
    "\n",
    "## Mexico \n",
    "\n",
    "me = gpd.GeoDataFrame()\n",
    "me['Point_B'] = gpd.GeoSeries(Point(-102.57635, 23.93537))\n",
    "me['id'] = 1\n",
    "\n",
    "mex = gpd.GeoDataFrame(pd.merge(mex, me, on = 'id'))\n",
    "mex['line'] = mex.apply(lambda x: LineString([x['Point_B'], x['center']]), axis=1)\n",
    "mex_gdf = gpd.GeoDataFrame(mex, geometry=mex['line'])\n",
    "\n",
    "## China\n",
    "\n",
    "ch = gpd.GeoDataFrame()\n",
    "ch['Point_B'] = gpd.GeoSeries(Point(103.88361, 36.55507))\n",
    "ch['id'] = 1\n",
    "\n",
    "chi = gpd.GeoDataFrame(pd.merge(chi, ch, on = 'id'))\n",
    "chi['line'] = chi.apply(lambda x: LineString([x['Point_B'], x['center']]), axis=1)\n",
    "chi_gdf = gpd.GeoDataFrame(chi, geometry=chi['line'])\n",
    "\n",
    "## South Africa \n",
    "\n",
    "so = gpd.GeoDataFrame()\n",
    "so['Point_B'] = gpd.GeoSeries(Point(25.04801, -28.94703))\n",
    "so['id'] = 1\n",
    "\n",
    "sou = gpd.GeoDataFrame(pd.merge(sou, so, on = 'id'))\n",
    "sou['line'] = sou.apply(lambda x: LineString([x['Point_B'], x['center']]), axis=1)\n",
    "sou_gdf = gpd.GeoDataFrame(sou, geometry=sou['line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac3664-9fc2-488b-987a-c58c3ddb1488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee8e993-ed23-4599-8949-a62713044bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs \n",
    "\n",
    "# Define the CartoPy CRS object.\n",
    "crs = ccrs.AlbersEqualArea()\n",
    "\n",
    "# This can be converted into a `proj4` string/dict compatible with GeoPandas\n",
    "crs_proj4 = crs.proj4_init\n",
    "world = world.to_crs(crs_proj4)\n",
    "tun_gdf.crs = \"epsg:4326\"\n",
    "mor_gdf.crs = \"epsg:4326\"\n",
    "mex_gdf.crs = \"epsg:4326\"\n",
    "chi_gdf.crs = \"epsg:4326\"\n",
    "sou_gdf.crs = \"epsg:4326\"\n",
    "## turn back to the right crs \n",
    "tun_gdf = tun_gdf.to_crs(crs_proj4)\n",
    "mor_gdf = mor_gdf.to_crs(crs_proj4)\n",
    "mex_gdf = mex_gdf.to_crs(crs_proj4)\n",
    "chi_gdf = chi_gdf.to_crs(crs_proj4)\n",
    "sou_gdf = sou_gdf.to_crs(crs_proj4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb75f2fa-25af-44fb-989b-b8d0c8ce20ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (14, 10))\n",
    "ax = fig.add_subplot(1,1,1, projection = ccrs.AlbersEqualArea())\n",
    "world.boundary.plot(ax =ax, color ='black', linewidth = .5)\n",
    "# m = dataset.query('Region == \"Europe\"').plot(column= \"CF\", ax =ax,\n",
    "#                                          transform = ccrs.PlateCarree(),\n",
    "#                                         legend = True, alpha = .3, cmap = 'Spectral',\n",
    "#                                         legend_kwds = {'label': \"Carbon footprint (t CO2 pc/yr)\",\n",
    "#                            'orientation': \"horizontal\",\n",
    "#                           'shrink': .3,\n",
    "#                           'pad': .01})\n",
    "\n",
    "\n",
    "## Tunisia \n",
    "world[world['name'] == 'Tunisia'].plot(ax =ax, color = '#F75C03', zorder = 0, alpha = .5)\n",
    "tun_gdf.plot(color = '#F75C03', ax =ax, label = 'Tunis (Tunisia)', linewidth = .7, alpha = .4)\n",
    "\n",
    "## Morocco \n",
    "world[world['name'] == 'Morocco'].plot(ax =ax, color = '#D90368', zorder = 0, alpha = .5)\n",
    "# mor.center.plot(ax = ax, color = '#D90368', alpha = 0.3, markersize = 2)\n",
    "mor_gdf.plot(color = '#D90368', ax =ax, label = 'Marrakesh (Morocco)', linewidth = .7, alpha = .4)\n",
    "\n",
    "# Mexico \n",
    "world[world['name'] == 'Mexico'].plot(ax =ax, color = '#820263', zorder = 0, alpha = .5)\n",
    "# mex.center.plot(ax = ax, color = '#820263', alpha = 0.3, markersize = 2)\n",
    "mex_gdf.plot(color = '#820263', ax =ax, label = 'Mexico city (Mexico)', linewidth = .7, alpha = .4)\n",
    "\n",
    "# China\n",
    "world[world['name'] == 'China'].plot(ax =ax, color = '#2F394D', zorder = 1, alpha = .5)\n",
    "# chi.center.plot(ax = ax, color = '#2F394D', alpha = 0.3, markersize = 2)\n",
    "chi_gdf.plot(color = '#2F394D', ax =ax, label = 'Beijing (China)', linewidth = .7, alpha = .4)\n",
    "\n",
    "# South Africa\n",
    "world[world['name'] == 'South Africa'].plot(ax =ax, color = '#6A5D7B', zorder = 1, alpha = .5)\n",
    "# sou.center.plot(ax = ax, color = '#6A5D7B', alpha = 0.3, markersize = 2)\n",
    "sou_gdf.plot(color = '#6A5D7B', ax =ax, label = 'Cape Town (South Africa)', linewidth = .7, alpha = .4)\n",
    "\n",
    "ax.set_global() # added following an answer to my question\n",
    "ax.add_feature(cartopy.feature.LAND, facecolor=(\"#FBFAF7\"))\n",
    "ax.add_feature(cartopy.feature.OCEAN, facecolor=(\"#D9DFE1\"))\n",
    "# ax.add_feature(cartopy.feature.COASTLINE)\n",
    "ax.add_feature(cartopy.feature.BORDERS, linestyle='--', alpha=.5, linewidth = .2)\n",
    "ax.spines['geo'].set_edgecolor('black')\n",
    "# plt.title('Virtual water imports of Global Southern cities', fontweight = 'light')\n",
    "plt.legend(frameon = False, bbox_to_anchor = (.61, 0.9))\n",
    "plt.savefig('../Figures/Map.png', dpi = 450)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
